{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:17:59.084452Z",
     "iopub.status.busy": "2022-07-15T10:17:59.083961Z",
     "iopub.status.idle": "2022-07-15T10:17:59.127435Z",
     "shell.execute_reply": "2022-07-15T10:17:59.126487Z",
     "shell.execute_reply.started": "2022-07-15T10:17:59.084360Z"
    }
   },
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:18:47.560362Z",
     "iopub.status.busy": "2022-07-15T10:18:47.559981Z",
     "iopub.status.idle": "2022-07-15T10:18:47.628781Z",
     "shell.execute_reply": "2022-07-15T10:18:47.627569Z",
     "shell.execute_reply.started": "2022-07-15T10:18:47.560330Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    " \n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:18:52.696455Z",
     "iopub.status.busy": "2022-07-15T10:18:52.696068Z",
     "iopub.status.idle": "2022-07-15T10:19:05.833381Z",
     "shell.execute_reply": "2022-07-15T10:19:05.832162Z",
     "shell.execute_reply.started": "2022-07-15T10:18:52.696425Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1234"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "random_seed=1234\n",
    "pl.seed_everything(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:19:18.301625Z",
     "iopub.status.busy": "2022-07-15T10:19:18.300994Z",
     "iopub.status.idle": "2022-07-15T10:19:40.609214Z",
     "shell.execute_reply": "2022-07-15T10:19:40.608273Z",
     "shell.execute_reply.started": "2022-07-15T10:19:18.301594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train_file = r'/kaggle/input/amex-agg-data-rev2/agg_train_all_rev2_rev.parquet'\n",
    "train_file = 'amex/agg_v3/agg_train_all_small.parquet'\n",
    "df=pd.read_parquet(train_file, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:19:45.805187Z",
     "iopub.status.busy": "2022-07-15T10:19:45.804820Z",
     "iopub.status.idle": "2022-07-15T10:19:46.560234Z",
     "shell.execute_reply": "2022-07-15T10:19:46.559125Z",
     "shell.execute_reply.started": "2022-07-15T10:19:45.805159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = ['B_10__last', 'B_10__mean', 'B_11__last', 'B_11__last__log', 'B_11__mean', 'B_11__mean__log', 'B_11__min', 'B_16__last', 'B_16__max', 'B_18__last', 'B_18__last__log', 'B_18__mean__log', 'B_18__min', 'B_19__last', 'B_1__last', 'B_1__max', 'B_1__mean', 'B_1__min', 'B_20__last', 'B_20__max', 'B_20__mean', 'B_22__last', 'B_22__last__log', 'B_22__max', 'B_22__mean', 'B_22__mean__log', 'B_23__last', 'B_23__last__log', 'B_23__mean', 'B_23__min', 'B_26__last__log', 'B_28__last', 'B_2__last', 'B_2__mean', 'B_2__min', 'B_30=0.0', 'B_30=1.0', 'B_30__nunique', 'B_33__last', 'B_33__max', 'B_33__mean', 'B_33__min', 'B_37__last', 'B_37__max', 'B_37__mean', 'B_38__last', 'B_3__last', 'B_3__last__log', 'B_3__max', 'B_3__mean', 'B_3__mean__log', 'B_3__min', 'B_40__last', 'B_40__last__log', 'B_40__mean__log', 'B_40__min', 'B_4__last', 'B_4__last__log', 'B_4__max', 'B_4__mean__log', 'B_5__last__log', 'B_6__last', 'B_6__min', 'B_7__last', 'B_7__max', 'B_7__mean', 'B_7__min', 'B_8__last', 'B_8__min', 'B_9__last', 'B_9__last__log', 'B_9__max', 'B_9__mean', 'B_9__mean__log', 'B_9__min', 'D_112__last', 'D_39__last', 'D_39__last__log', 'D_39__max', 'D_41__last', 'D_41__last__log', 'D_41__max', 'D_42__last', 'D_42__max', 'D_42__mean', 'D_42__min', 'D_43__last', 'D_43__max', 'D_43__mean', 'D_43__mean__log', 'D_44__last', 'D_44__last__log', 'D_44__max', 'D_44__mean', 'D_44__mean__log', 'D_44__min', 'D_45__last', 'D_45__last__log', 'D_45__max', 'D_45__mean', 'D_45__mean__log', 'D_45__min', 'D_48__last', 'D_48__max', 'D_48__mean', 'D_48__min', 'D_52__last', 'D_52__max', 'D_52__mean', 'D_52__min', 'D_53__max', 'D_55__last', 'D_58__last', 'D_58__min', 'D_61__last', 'D_61__max', 'D_61__mean', 'D_61__min', 'D_62__last', 'D_62__max', 'D_62__mean', 'D_62__min', 'D_70__max', 'D_74__last', 'D_74__max', 'D_74__mean', 'D_75__last', 'D_75__max', 'D_75__mean', 'D_77__last', 'D_77__max', 'D_77__mean', 'D_77__min', 'D_78__max', 'D_78__mean', 'D_84__mean', 'P_2__last', 'P_2__max', 'P_2__mean', 'P_2__min', 'P_3__last', 'P_3__mean', 'P_3__min', 'R_10__max', 'R_10__mean', 'R_1__last', 'R_1__max', 'R_1__mean', 'R_2__last', 'R_2__max', 'R_2__mean', 'R_3__max', 'R_3__mean', 'R_3__min', 'R_4__last', 'R_4__max', 'R_4__mean', 'R_5__last', 'R_5__max', 'R_5__mean', 'R_6__max', 'R_6__mean', 'R_7__mean', 'R_8__mean', 'S_15__max', 'S_15__mean', 'S_22__last', 'S_23__last', 'S_25__mean', 'S_25__min', 'S_3__last', 'S_3__max', 'S_3__mean', 'S_3__min', 'S_7__last', 'S_7__max', 'S_7__mean', 'S_8__last', 'S_8__mean', 'S_8__min']\n",
    "\n",
    "\n",
    "len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_cnt = df[feats].isna().sum()\n",
    "display(na_cnt[na_cnt>0])\n",
    "del na_cnt\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define autoencoder-mlp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:19:49.950150Z",
     "iopub.status.busy": "2022-07-15T10:19:49.949787Z",
     "iopub.status.idle": "2022-07-15T10:19:49.969212Z",
     "shell.execute_reply": "2022-07-15T10:19:49.968073Z",
     "shell.execute_reply.started": "2022-07-15T10:19:49.950123Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://pytorch-forecasting.readthedocs.io/en/latest/_modules/pytorch_forecasting/models/mlp/submodules.html#FullyConnectedModule\n",
    "#https://www.kaggle.com/c/jane-street-market-prediction/discussion/224348\n",
    "#https://www.kaggle.com/code/gogo827jz/jane-street-supervised-autoencoder-mlp/notebook?scriptVersionId=73762661\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class AE_MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        output_size: int,\n",
    "        hidden_sizes: list,\n",
    "        dropouts: list,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.dropouts = dropouts\n",
    "        \n",
    "        #----normalize input data--------------\n",
    "        self.bn0 = nn.BatchNorm1d(input_size)\n",
    "        \n",
    "        #---encoder layer----------------\n",
    "        self.encoder = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]), \n",
    "                                     nn.BatchNorm1d(hidden_sizes[0]), \n",
    "                                     nn.SiLU()\n",
    "                                    )\n",
    "        #---decoder layer----------------\n",
    "        self.decoder = nn.Sequential(nn.Dropout(dropouts[0]), \n",
    "                                     nn.Linear(hidden_sizes[0], input_size) \n",
    "                                    )\n",
    "        #----AE output layer-------------\n",
    "        self.ae_out = nn.Sequential(nn.Linear(input_size, hidden_sizes[1]), \n",
    "                                    nn.BatchNorm1d(hidden_sizes[1]), \n",
    "                                    nn.SiLU(), \n",
    "                                    nn.Dropout(dropouts[1]), \n",
    "                                    nn.Linear(hidden_sizes[1], output_size),\n",
    "                                    nn.Sigmoid(), #for binary classification loss function BCELoss\n",
    "                                    )\n",
    "        #---MLP--------------------------\n",
    "                \n",
    "        # input layer\n",
    "        size2 = input_size+hidden_sizes[0]\n",
    "        module_list = [nn.BatchNorm1d(size2), \n",
    "                       nn.Dropout(dropouts[2]), \n",
    "                       nn.Linear(size2, hidden_sizes[2]), \n",
    "                       nn.BatchNorm1d(hidden_sizes[2]), \n",
    "                       nn.SiLU(), \n",
    "                       nn.Dropout(dropouts[2])]\n",
    "    \n",
    "        # hidden layers\n",
    "        for i in range(3, len(hidden_sizes)):\n",
    "            module_list.extend([nn.Linear(hidden_sizes[i-1], hidden_sizes[i]), \n",
    "                                nn.BatchNorm1d(hidden_sizes[i]), \n",
    "                                nn.SiLU(), \n",
    "                                nn.Dropout(dropouts[i])]\n",
    "                              )\n",
    "        # output layer\n",
    "        module_list.extend([nn.Linear(hidden_sizes[-1], output_size), \n",
    "                           nn.Sigmoid()])\n",
    "\n",
    "        self.mlp = nn.Sequential(*module_list)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = self.bn0(x)\n",
    "        encoder = self.encoder(x0)\n",
    "        decoder = self.decoder(encoder)\n",
    "        out_ae = self.ae_out(decoder)\n",
    "        \n",
    "        #x0 shape is n*m - n samples, m features\n",
    "        #encoder is n*k - n samples, k features\n",
    "        #x1 is n*(k+m) - n samples, (k+m) features\n",
    "        #if x0 is n*w*m with w as the width for 3d array, the output will be n*w*(k+m)\n",
    "        x1 = torch.cat((x0, encoder), dim = -1) #\n",
    "        out = self.mlp(x1)\n",
    "\n",
    "        return decoder, out_ae, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:19:51.807443Z",
     "iopub.status.busy": "2022-07-15T10:19:51.806637Z",
     "iopub.status.idle": "2022-07-15T10:19:51.818205Z",
     "shell.execute_reply": "2022-07-15T10:19:51.817097Z",
     "shell.execute_reply.started": "2022-07-15T10:19:51.807396Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import (Dataset, DataLoader)\n",
    "  \n",
    "\n",
    "class TS_Data(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y): \n",
    "        \n",
    "        features = torch.FloatTensor(X)\n",
    "        targets = torch.FloatTensor(y)\n",
    "        \n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "        self.n_samples = X.shape[0]\n",
    "        self.n_features = X.shape[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "\n",
    "        x = self.features[idx]\n",
    "        y = self.targets[idx]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "\n",
    "def load_data(X, y, batch_size, n_workers=0, shuffle=False):\n",
    "    data = TS_Data(X, y)\n",
    "    \n",
    "    loader = DataLoader(data, batch_size=batch_size, num_workers=n_workers, shuffle=shuffle)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperopt parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:19:55.519461Z",
     "iopub.status.busy": "2022-07-15T10:19:55.518468Z",
     "iopub.status.idle": "2022-07-15T10:19:55.532052Z",
     "shell.execute_reply": "2022-07-15T10:19:55.530612Z",
     "shell.execute_reply.started": "2022-07-15T10:19:55.519413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 10, 500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_rates = np.concatenate((np.arange(0.00001, 0.0001, 0.00001),  \n",
    "                           np.arange(0.0001, 0.001, 0.0001), \n",
    "                           np.arange(0.001, 0.01, 0.001), \n",
    "                           np.arange(0.01, 0.05, 0.01)\n",
    "                          ), \n",
    "                          axis=0)\n",
    "hidden_sizes=[32, 48, 64, 96, 128, 256, 448, 512, 896, 1024] \n",
    "encoder_outputsize = range(5, 101)\n",
    "dropouts = np.round(np.arange(0.001, 0.501, 0.001), 4)\n",
    "\n",
    "len(learn_rates), len(hidden_sizes), len(dropouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:23:11.024738Z",
     "iopub.status.busy": "2022-07-15T10:23:11.024282Z",
     "iopub.status.idle": "2022-07-15T10:23:11.511141Z",
     "shell.execute_reply": "2022-07-15T10:23:11.510044Z",
     "shell.execute_reply.started": "2022-07-15T10:23:11.024691Z"
    }
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "import numpy as np\n",
    "space  = { \n",
    "             'batch_size': hp.choice('batch_size', [128*i for i in [1, 2, 4, 8, 16, 20, 32, 40, 80, 100]]),\n",
    "             'num_epochs':hp.choice('num_epochs', [50, 60, 100, 150, 200]),\n",
    "             'learning_rate':hp.choice('learning_rate', learn_rates),\n",
    "             'hidden_size1':hp.choice('hidden_size1', encoder_outputsize),\n",
    "             'hidden_size2':hp.choice('hidden_size2', hidden_sizes),\n",
    "             'hidden_size3':hp.choice('hidden_size3', hidden_sizes),\n",
    "             'hidden_size4':hp.choice('hidden_size4', hidden_sizes),\n",
    "             'hidden_size5':hp.choice('hidden_size5', hidden_sizes),\n",
    "             'hidden_size6':hp.choice('hidden_size6', hidden_sizes),\n",
    "             'dropout1':  hp.choice('dropout1', dropouts), \n",
    "             'dropout2':  hp.choice('dropout2', dropouts), \n",
    "             'dropout3':  hp.choice('dropout3', dropouts), \n",
    "             'dropout4':  hp.choice('dropout4', dropouts), \n",
    "             'dropout5':  hp.choice('dropout5', dropouts), \n",
    "             'dropout6':  hp.choice('dropout6', dropouts), \n",
    "    \n",
    "            }                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:23:56.864482Z",
     "iopub.status.busy": "2022-07-15T10:23:56.864071Z",
     "iopub.status.idle": "2022-07-15T10:23:56.874899Z",
     "shell.execute_reply": "2022-07-15T10:23:56.873955Z",
     "shell.execute_reply.started": "2022-07-15T10:23:56.864451Z"
    }
   },
   "outputs": [],
   "source": [
    "# @yunchonggan's fast metric implementation\n",
    "# From https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "# https://www.kaggle.com/code/ambrosm/amex-lightgbm-quickstart\n",
    "def amex_metric(y_true: np.array, y_pred: np.array) -> float:\n",
    "\n",
    "    # count of positives and negatives\n",
    "    n_pos = y_true.sum()\n",
    "    n_neg = y_true.shape[0] - n_pos\n",
    "\n",
    "    # sorting by descring prediction values\n",
    "    indices = np.argsort(y_pred)[::-1]\n",
    "    preds, target = y_pred[indices], y_true[indices]\n",
    "\n",
    "    # filter the top 4% by cumulative row weights\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_filter = cum_norm_weight <= 0.04\n",
    "\n",
    "    # default rate captured at 4%\n",
    "    d = target[four_pct_filter].sum() / n_pos\n",
    "\n",
    "    # weighted gini coefficient\n",
    "    lorentz = (target / n_pos).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    # max weighted gini coefficient\n",
    "    gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n",
    "\n",
    "    # normalized weighted gini coefficient\n",
    "    g = gini / gini_max\n",
    "\n",
    "    return 0.5 * (g + d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:24:27.927576Z",
     "iopub.status.busy": "2022-07-15T10:24:27.927149Z",
     "iopub.status.idle": "2022-07-15T10:24:29.632500Z",
     "shell.execute_reply": "2022-07-15T10:24:29.631225Z",
     "shell.execute_reply.started": "2022-07-15T10:24:27.927544Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df[feats]\n",
    "y = df[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:24:35.065974Z",
     "iopub.status.busy": "2022-07-15T10:24:35.065151Z",
     "iopub.status.idle": "2022-07-15T10:24:35.538913Z",
     "shell.execute_reply": "2022-07-15T10:24:35.537782Z",
     "shell.execute_reply.started": "2022-07-15T10:24:35.065934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:24:37.083558Z",
     "iopub.status.busy": "2022-07-15T10:24:37.082563Z",
     "iopub.status.idle": "2022-07-15T10:24:37.090572Z",
     "shell.execute_reply": "2022-07-15T10:24:37.089383Z",
     "shell.execute_reply.started": "2022-07-15T10:24:37.083510Z"
    }
   },
   "outputs": [],
   "source": [
    "skf = KFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:24:49.295927Z",
     "iopub.status.busy": "2022-07-15T10:24:49.295496Z",
     "iopub.status.idle": "2022-07-15T10:24:49.343312Z",
     "shell.execute_reply": "2022-07-15T10:24:49.342289Z",
     "shell.execute_reply.started": "2022-07-15T10:24:49.295889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=3, random_state=None, shuffle=False)\n",
      "0    0.740565\n",
      "1    0.259435\n",
      "Name: target, dtype: float64\n",
      "0    0.741317\n",
      "1    0.258683\n",
      "Name: target, dtype: float64\n",
      "0    0.739552\n",
      "1    0.260448\n",
      "Name: target, dtype: float64\n",
      "0    0.741824\n",
      "1    0.258176\n",
      "Name: target, dtype: float64\n",
      "0    0.743082\n",
      "1    0.256918\n",
      "Name: target, dtype: float64\n",
      "0    0.740059\n",
      "1    0.259941\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(skf)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index), len(test_index)/(len(test_index)+len(train_index)))\n",
    "    print(y.iloc[test_index]['target'].value_counts()/len(test_index)) \n",
    "    print(y.iloc[train_index]['target'].value_counts()/len(train_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:24:50.767107Z",
     "iopub.status.busy": "2022-07-15T10:24:50.766662Z",
     "iopub.status.idle": "2022-07-15T10:24:50.774622Z",
     "shell.execute_reply": "2022-07-15T10:24:50.773524Z",
     "shell.execute_reply.started": "2022-07-15T10:24:50.767073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:24:52.522988Z",
     "iopub.status.busy": "2022-07-15T10:24:52.522605Z",
     "iopub.status.idle": "2022-07-15T10:24:52.528340Z",
     "shell.execute_reply": "2022-07-15T10:24:52.527243Z",
     "shell.execute_reply.started": "2022-07-15T10:24:52.522959Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss, MSELoss, BCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = 'amex/agg_v3/amex-hyperopt-aemlp-180feats.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:28:50.498307Z",
     "iopub.status.busy": "2022-07-15T10:28:50.497249Z",
     "iopub.status.idle": "2022-07-15T10:28:50.521623Z",
     "shell.execute_reply": "2022-07-15T10:28:50.520633Z",
     "shell.execute_reply.started": "2022-07-15T10:28:50.498262Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_dict = []\n",
    "\n",
    "def score(params):\n",
    "    pl.seed_everything(1)\n",
    "#     print(params)\n",
    "    \n",
    "    learning_rate = params['learning_rate']\n",
    "    num_epochs = params['num_epochs']\n",
    "    batch_size = params['batch_size']\n",
    "    h_sizes = [params[f'hidden_size{i}'] for i in range(1,7)]\n",
    "    drop_list = [params[f'dropout{i}'] for i in range(1,7)]\n",
    "\n",
    "\n",
    "    losses = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        \n",
    "        #----start: data prep-------------------------------------\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        #----end: data prep-------------------------------------\n",
    "        \n",
    "#         print(X_train.shape, X_test.shape)\n",
    "        \n",
    "        \n",
    "        scaler_ = StandardScaler()\n",
    "        scaler_.fit(X_train)\n",
    "        # minmax_scaler.fit_transform(X_train[x_cols])\n",
    "\n",
    "        train_loader = load_data(scaler_.transform(X_train), y_train['target'].values, \n",
    "                                 batch_size=batch_size, n_workers=0, shuffle=False)\n",
    "\n",
    "        test_loader = load_data(scaler_.transform(X_test), y_test['target'].values, \n",
    "                                 batch_size=batch_size, n_workers=0, shuffle=False)\n",
    "        #----end: data prep-------------------------------------\n",
    "\n",
    "\n",
    "        model = AE_MLP(input_size=len(feats), output_size=1, \n",
    "                       hidden_sizes=h_sizes, \n",
    "                       dropouts = drop_list)\n",
    "\n",
    "        model = model.to(device)\n",
    "\n",
    "        # optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)  \n",
    "        optimizer = torch.optim.RMSprop([\n",
    "                {'params': model.encoder.parameters()},\n",
    "                {'params': model.decoder.parameters()},\n",
    "                {'params': model.ae_out.parameters()},\n",
    "                {'params': model.mlp.parameters()},\n",
    "            ], lr=learning_rate)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                                  max_lr=1e-2, epochs=num_epochs, steps_per_epoch=len(train_loader))\n",
    "        \n",
    "        decoder_loss = MSELoss()\n",
    "        out_ae_loss = BCELoss()\n",
    "        out_loss = BCELoss()\n",
    "\n",
    "\n",
    "        #------train models--------------------------\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "\n",
    "                features = features.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                ### FORWARD AND BACK PROP\n",
    "                decoder, out_ae, out = model(features)\n",
    "                decoder_cost = decoder_loss(decoder, features)\n",
    "                out_ae_cost = out_ae_loss(out_ae.squeeze(), targets)  \n",
    "                out_cost = out_loss(out.squeeze(), targets) #squeeze the n_samples*1 2d array to 1d array of n_samples\n",
    "                total_cost = (decoder_cost + out_ae_cost + out_cost)/3\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                total_cost.backward()\n",
    "\n",
    "                ### UPDATE MODEL PARAMETERS\n",
    "                optimizer.step()\n",
    "\n",
    "        #-----eval models-------------------------------\n",
    "        model.eval()\n",
    "\n",
    "        y_preds = []\n",
    "        y_trues = []\n",
    "        with torch.no_grad():\n",
    "            for features, targets in test_loader:\n",
    "                features = features.to(device)\n",
    "                targets = targets.to(device)\n",
    "                _, _, outputs = model(features)\n",
    "                y_preds.extend(outputs.squeeze().cpu().numpy())\n",
    "                y_trues.extend(targets.squeeze().cpu().numpy())\n",
    "\n",
    "        #-----start: train mlp---------------------------------------\n",
    "        \n",
    "        #-----end: train mlp---------------------------------------\n",
    "#         loss = roc_auc_score(y_trues, y_preds)\n",
    "#         loss = amex_metric(y_test, \n",
    "#                            pd.DataFrame(data={'prediction': y_preds}))\n",
    "        y_preds = np.array(y_preds)\n",
    "    \n",
    "        loss = amex_metric(y_test['target'].values, y_preds)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        \n",
    "    loss = np.mean(losses)\n",
    "#     print(loss)\n",
    "    loss_dict.append({'params': params, 'losses': losses, 'mean_loss': loss})\n",
    "    if len(loss_dict)%3==0:\n",
    "        pd.DataFrame(data=loss_dict).to_excel(log_file, index=False)\n",
    "    return {'loss': -loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:28:53.527497Z",
     "iopub.status.busy": "2022-07-15T10:28:53.527063Z",
     "iopub.status.idle": "2022-07-15T10:28:53.535142Z",
     "shell.execute_reply": "2022-07-15T10:28:53.534122Z",
     "shell.execute_reply.started": "2022-07-15T10:28:53.527461Z"
    }
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, anneal, rand\n",
    "from functools import partial\n",
    "def optimize(space, evals, cores, trials, optimizer=tpe.suggest, random_state=1234, n_startup_jobs=10):\n",
    "    algo = partial(optimizer, n_startup_jobs=n_startup_jobs)\n",
    "    best = fmin(score, space, algo=algo, max_evals=evals, trials = trials)\n",
    "    print(best)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:28:53.772468Z",
     "iopub.status.busy": "2022-07-15T10:28:53.772063Z",
     "iopub.status.idle": "2022-07-15T10:28:53.777934Z",
     "shell.execute_reply": "2022-07-15T10:28:53.776795Z",
     "shell.execute_reply.started": "2022-07-15T10:28:53.772436Z"
    }
   },
   "outputs": [],
   "source": [
    "cores = 4\n",
    "n=500\n",
    "verbose = False\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T10:28:54.155932Z",
     "iopub.status.busy": "2022-07-15T10:28:54.155241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                         | 0/500 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                         | 1/500 [36:33<304:00:31, 2193.25s/it, best loss: -0.7549057862532833]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                        | 2/500 [42:35<154:24:20, 1116.19s/it, best loss: -0.7790104946200208]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏                                      | 3/500 [1:13:38<201:10:07, 1457.16s/it, best loss: -0.7790104946200208]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▎                                      | 4/500 [1:37:44<200:09:10, 1452.72s/it, best loss: -0.7790104946200208]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                      | 5/500 [1:45:16<150:07:46, 1091.85s/it, best loss: -0.7792881270511458]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                      | 6/500 [2:07:31<161:11:55, 1174.73s/it, best loss: -0.7792881270511458]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▌                                       | 7/500 [2:14:46<127:45:25, 932.91s/it, best loss: -0.7792881270511458]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▋                                       | 8/500 [2:26:58<118:42:54, 868.65s/it, best loss: -0.7792881270511458]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▋                                       | 9/500 [2:38:50<111:49:57, 819.95s/it, best loss: -0.7792881270511458]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▊                                      | 10/500 [2:56:35<121:52:27, 895.40s/it, best loss: -0.7792881270511458]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▊                                      | 11/500 [3:04:07<103:11:38, 759.71s/it, best loss: -0.7792881270511458]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▉                                       | 12/500 [3:10:09<86:36:02, 638.86s/it, best loss: -0.7792881270511458]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█                                      | 13/500 [3:34:02<118:57:28, 879.36s/it, best loss: -0.7796073492974597]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█                                     | 14/500 [3:57:54<141:15:56, 1046.41s/it, best loss: -0.7796588107492209]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▏                                    | 15/500 [4:21:45<156:35:29, 1162.33s/it, best loss: -0.7796588107492209]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▏                                    | 16/500 [4:46:05<168:18:01, 1251.82s/it, best loss: -0.7806770248622671]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▎                                    | 17/500 [5:10:17<176:01:22, 1311.97s/it, best loss: -0.7806770248622671]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▎                                    | 18/500 [5:34:51<182:12:01, 1360.83s/it, best loss: -0.7806770248622671]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▍                                    | 19/500 [5:59:04<185:29:56, 1388.35s/it, best loss: -0.7806770248622671]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    }
   ],
   "source": [
    "best_param = optimize(space,\n",
    "                      evals = n,\n",
    "                      optimizer=tpe.suggest,\n",
    "                      cores = cores,\n",
    "                      trials = trials, random_state=1234, \n",
    "                      n_startup_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=loss_dict).to_excel(log_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
