{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMEX Default Competition - Feature Engineering\n",
    "\n",
    "\n",
    "- This notebook does the following:\n",
    "\n",
    "    - aggregating data by customer_ID\n",
    "        - get the min, max, mean, std, first, last for each numeric features\n",
    "            - then create a feature that checks if the last number if with 1.5 standard deviation of mean\n",
    "        - get the unique count for categorical features \n",
    "\n",
    "    \n",
    "- the raw data used for this notebook is generated by:\n",
    "    - Process Amex Train Data to Parquet Format: https://www.kaggle.com/code/xxxxyyyy80008/process-amex-train-data-to-parquet-format\n",
    "    - datasets can be accessed here:\n",
    "        - train file: https://www.kaggle.com/datasets/xxxxyyyy80008/amex-train-20220706\n",
    "        - test file: https://www.kaggle.com/datasets/xxxxyyyy80008/amex-test-20020706\n",
    "    \n",
    "- this notebook also used some insights from this notebook:\n",
    "     - AMEX - Train Data EDA - Dask for Fast Analysis: https://www.kaggle.com/code/xxxxyyyy80008/amex-train-data-eda-dask-for-fast-analysis\n",
    "     \n",
    "- the data output of this notebook can be accessed here:\n",
    "     - train data: https://www.kaggle.com/datasets/xxxxyyyy80008/amex-agg-data-rev2\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-12T01:15:15.181312Z",
     "iopub.status.busy": "2022-07-12T01:15:15.180928Z",
     "iopub.status.idle": "2022-07-12T01:15:15.192646Z",
     "shell.execute_reply": "2022-07-12T01:15:15.190939Z",
     "shell.execute_reply.started": "2022-07-12T01:15:15.181281Z"
    }
   },
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T01:15:51.923683Z",
     "iopub.status.busy": "2022-07-12T01:15:51.923302Z",
     "iopub.status.idle": "2022-07-12T01:15:51.930788Z",
     "shell.execute_reply": "2022-07-12T01:15:51.929647Z",
     "shell.execute_reply.started": "2022-07-12T01:15:51.923654Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from dateutil import relativedelta\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T01:15:53.803432Z",
     "iopub.status.busy": "2022-07-12T01:15:53.802471Z",
     "iopub.status.idle": "2022-07-12T01:16:07.203670Z",
     "shell.execute_reply": "2022-07-12T01:16:07.202611Z",
     "shell.execute_reply.started": "2022-07-12T01:15:53.803365Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1234"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "random_seed=1234\n",
    "pl.seed_everything(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregate by customer id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T01:16:07.206620Z",
     "iopub.status.busy": "2022-07-12T01:16:07.205740Z",
     "iopub.status.idle": "2022-07-12T01:16:07.231128Z",
     "shell.execute_reply": "2022-07-12T01:16:07.230306Z",
     "shell.execute_reply.started": "2022-07-12T01:16:07.206589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n"
     ]
    }
   ],
   "source": [
    "all_cols = ['customer_ID', 'S_2', 'P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'R_2', 'D_46', 'D_47', 'D_48', 'D_49', 'B_6', 'B_7', 'B_8', 'D_50', 'D_51', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5', 'B_11', 'S_6', 'D_54', 'R_4', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5', 'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'D_63', 'D_64', 'D_65', 'B_16', 'B_17', 'B_18', 'B_19', 'D_66', 'B_20', 'D_68', 'S_12', 'R_6', 'S_13', 'B_21', 'D_69', 'B_22', 'D_70', 'D_71', 'D_72', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74', 'D_75', 'D_76', 'B_24', 'R_7', 'D_77', 'B_25', 'B_26', 'D_78', 'D_79', 'R_8', 'R_9', 'S_16', 'D_80', 'R_10', 'R_11', 'B_27', 'D_81', 'D_82', 'S_17', 'R_12', 'B_28', 'R_13', 'D_83', 'R_14', 'R_15', 'D_84', 'R_16', 'B_29', 'B_30', 'S_18', 'D_86', 'D_87', 'R_17', 'R_18', 'D_88', 'B_31', 'S_19', 'R_19', 'B_32', 'S_20', 'R_20', 'R_21', 'B_33', 'D_89', 'R_22', 'R_23', 'D_91', 'D_92', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'D_102', 'D_103', 'D_104', 'D_105', 'D_106', 'D_107', 'B_36', 'B_37', 'R_26', 'R_27', 'B_38', 'D_108', 'D_109', 'D_110', 'D_111', 'B_39', 'D_112', 'B_40', 'S_27', 'D_113', 'D_114', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_127', 'D_128', 'D_129', 'B_41', 'B_42', 'D_130', 'D_131', 'D_132', 'D_133', 'R_28', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', 'D_143', 'D_144', 'D_145']\n",
    "\n",
    "id_feats = ['customer_ID']\n",
    "date_col =  'S_2'\n",
    "num_cat_feats = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_66', 'D_68', 'B_31']\n",
    "str_cat_feats = ['D_63', 'D_64', ]\n",
    "float_feats = ['B_1', 'B_10', 'B_11', 'B_12', 'B_13', 'B_14', 'B_15', 'B_16', 'B_17', 'B_18', 'B_19', 'B_2', 'B_20', 'B_21', 'B_22', 'B_23', 'B_24', 'B_25', 'B_26', 'B_27', 'B_28', 'B_29', 'B_3', 'B_30', 'B_32', 'B_33', 'B_36', 'B_37', 'B_38', 'B_39', 'B_4', 'B_40', 'B_41', 'B_42', 'B_5', 'B_6', 'B_7', 'B_8', 'B_9', 'D_102', 'D_103', 'D_104', 'D_105', 'D_106', 'D_107', 'D_108', 'D_109', 'D_110', 'D_111', 'D_112', 'D_113', 'D_114', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_127', 'D_128', 'D_129', 'D_130', 'D_131', 'D_132', 'D_133', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', 'D_143', 'D_144', 'D_145', 'D_39', 'D_41', 'D_42', 'D_43', 'D_44', 'D_45', 'D_46', 'D_47', 'D_48', 'D_49', 'D_50', 'D_51', 'D_52', 'D_53', 'D_54', 'D_55', 'D_56', 'D_58', 'D_59', 'D_60', 'D_61', 'D_62', 'D_65', 'D_66', 'D_68', 'D_69', 'D_70', 'D_71', 'D_72', 'D_73', 'D_74', 'D_75', 'D_76', 'D_77', 'D_78', 'D_79', 'D_80', 'D_81', 'D_82', 'D_83', 'D_84', 'D_86', 'D_87', 'D_88', 'D_89', 'D_91', 'D_92', 'D_93', 'D_94', 'D_96', 'P_2', 'P_3', 'P_4', 'R_1', 'R_10', 'R_11', 'R_12', 'R_13', 'R_14', 'R_15', 'R_16', 'R_17', 'R_18', 'R_19', 'R_2', 'R_20', 'R_21', 'R_22', 'R_23', 'R_24', 'R_25', 'R_26', 'R_27', 'R_28', 'R_3', 'R_4', 'R_5', 'R_6', 'R_7', 'R_8', 'R_9', 'S_11', 'S_12', 'S_13', 'S_15', 'S_16', 'S_17', 'S_18', 'S_19', 'S_20', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'S_27', 'S_3', 'S_5', 'S_6', 'S_7', 'S_8', 'S_9']\n",
    "int_feats = ['B_31']\n",
    "\n",
    "print(len(float_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T01:16:07.272209Z",
     "iopub.status.busy": "2022-07-12T01:16:07.271881Z",
     "iopub.status.idle": "2022-07-12T01:16:07.281871Z",
     "shell.execute_reply": "2022-07-12T01:16:07.280856Z",
     "shell.execute_reply.started": "2022-07-12T01:16:07.272180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train_file = '/kaggle/input/amex-train-20220706/train.parquet'\n",
    "# test_file = '/kaggle/input/amex-test-20020706/amex_test_20220706.parquet'\n",
    "\n",
    "train_file = 'amex/train.parquet'\n",
    "test_file = 'amex/amex_test_20220706.parquet'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "df = pd.read_parquet(test_file,  engine='pyarrow')\n",
    "\n",
    "for c in cat_feats:\n",
    "    print(c, '-'*80)\n",
    "    display(df[c].value_counts())\n",
    "float_cols = df.select_dtypes(include=['float64', 'float32']).columns.tolist()\n",
    "#---convert int64 to int32\n",
    "int_cols = df.select_dtypes(include=['int64', 'int32']).columns.tolist()\n",
    "float_cols.sort()\n",
    "print(float_cols)\n",
    "int_cols.sort()\n",
    "print(int_cols)\n",
    "print(len(float_cols), len(int_cols), len(all_cols))\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train file processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps =  1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_folder = 'amex/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>mean2std</th>\n",
       "      <th>last2max</th>\n",
       "      <th>last2min</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B_1</th>\n",
       "      <td>0.008231</td>\n",
       "      <td>0.095357</td>\n",
       "      <td>0.038720</td>\n",
       "      <td>0.020624</td>\n",
       "      <td>0.027948</td>\n",
       "      <td>0.033219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.402201</td>\n",
       "      <td>1.754015</td>\n",
       "      <td>0.065136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_10</th>\n",
       "      <td>0.033851</td>\n",
       "      <td>0.272729</td>\n",
       "      <td>0.130737</td>\n",
       "      <td>0.027920</td>\n",
       "      <td>0.121036</td>\n",
       "      <td>0.096286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333524</td>\n",
       "      <td>0.516970</td>\n",
       "      <td>0.083319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_11</th>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.074862</td>\n",
       "      <td>0.027941</td>\n",
       "      <td>0.017387</td>\n",
       "      <td>0.015933</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.430243</td>\n",
       "      <td>2.853625</td>\n",
       "      <td>0.054636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_12</th>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.032243</td>\n",
       "      <td>0.020392</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>0.016311</td>\n",
       "      <td>0.017545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.243477</td>\n",
       "      <td>0.526921</td>\n",
       "      <td>0.017443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_13</th>\n",
       "      <td>0.010968</td>\n",
       "      <td>0.053904</td>\n",
       "      <td>0.033493</td>\n",
       "      <td>0.011981</td>\n",
       "      <td>0.028056</td>\n",
       "      <td>0.028014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.308872</td>\n",
       "      <td>1.011068</td>\n",
       "      <td>0.033255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_5</th>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.062134</td>\n",
       "      <td>0.024643</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>0.009989</td>\n",
       "      <td>0.012489</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.575202</td>\n",
       "      <td>3.867261</td>\n",
       "      <td>0.054910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_6</th>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.009933</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>0.007524</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.437023</td>\n",
       "      <td>4.407298</td>\n",
       "      <td>0.009150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_7</th>\n",
       "      <td>0.101917</td>\n",
       "      <td>0.258384</td>\n",
       "      <td>0.166948</td>\n",
       "      <td>0.048958</td>\n",
       "      <td>0.147449</td>\n",
       "      <td>0.137705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.258638</td>\n",
       "      <td>0.230850</td>\n",
       "      <td>0.138686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_8</th>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.599643</td>\n",
       "      <td>0.284040</td>\n",
       "      <td>0.128605</td>\n",
       "      <td>0.323709</td>\n",
       "      <td>0.318551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.389655</td>\n",
       "      <td>1.428870</td>\n",
       "      <td>0.355751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_9</th>\n",
       "      <td>0.007348</td>\n",
       "      <td>0.044297</td>\n",
       "      <td>0.023754</td>\n",
       "      <td>0.014246</td>\n",
       "      <td>0.016994</td>\n",
       "      <td>0.012272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.553752</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.028727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           min       max      mean       std     first      last  mean2std  \\\n",
       "feat                                                                         \n",
       "B_1   0.008231  0.095357  0.038720  0.020624  0.027948  0.033219       1.0   \n",
       "B_10  0.033851  0.272729  0.130737  0.027920  0.121036  0.096286       1.0   \n",
       "B_11  0.003701  0.074862  0.027941  0.017387  0.015933  0.021256       1.0   \n",
       "B_12  0.008455  0.032243  0.020392  0.005491  0.016311  0.017545       1.0   \n",
       "B_13  0.010968  0.053904  0.033493  0.011981  0.028056  0.028014       1.0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "S_5   0.002369  0.062134  0.024643  0.018744  0.009989  0.012489       1.0   \n",
       "S_6   0.000837  0.009933  0.006124  0.003102  0.007524  0.006561       1.0   \n",
       "S_7   0.101917  0.258384  0.166948  0.048958  0.147449  0.137705       1.0   \n",
       "S_8   0.005128  0.599643  0.284040  0.128605  0.323709  0.318551       1.0   \n",
       "S_9   0.007348  0.044297  0.023754  0.014246  0.016994  0.012272       0.0   \n",
       "\n",
       "      last2max  last2min     range  \n",
       "feat                                \n",
       "B_1   0.402201  1.754015  0.065136  \n",
       "B_10  0.333524  0.516970  0.083319  \n",
       "B_11  0.430243  2.853625  0.054636  \n",
       "B_12  0.243477  0.526921  0.017443  \n",
       "B_13  0.308872  1.011068  0.033255  \n",
       "...        ...       ...       ...  \n",
       "S_5   0.575202  3.867261  0.054910  \n",
       "S_6   0.437023  4.407298  0.009150  \n",
       "S_7   0.258638  0.230850  0.138686  \n",
       "S_8   0.389655  1.428870  0.355751  \n",
       "S_9   0.553752  0.269000  0.028727  \n",
       "\n",
       "[185 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df = pd.read_csv(f'amex/train_agg_median.csv', index_col=0)\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T01:22:37.765469Z",
     "iopub.status.busy": "2022-07-12T01:22:37.765046Z",
     "iopub.status.idle": "2022-07-12T02:36:09.871839Z",
     "shell.execute_reply": "2022-07-12T02:36:09.869161Z",
     "shell.execute_reply.started": "2022-07-12T01:22:37.765435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 29min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "agg_files = []\n",
    "stats = []\n",
    "for c in float_feats:\n",
    "    df = dd.read_parquet(test_file, columns=['customer_ID', 'S_2',c], engine='pyarrow')\n",
    "    x = df.compute().sort_values(by='S_2', ascending=True).groupby(\"customer_ID\").agg({c: ['min', 'max', 'mean', 'std', 'first','last']})\n",
    "    x.columns = [f'{c1}__{c2}' for c1, c2 in x.columns]\n",
    "    \n",
    "    x[f'{c}__mean2std'] = (x[f'{c}__last'] >= (x[f'{c}__mean']-1.5*x[f'{c}__std'])) & (x[f'{c}__last'] <= (x[f'{c}__mean']+1.5*x[f'{c}__std']))\n",
    "    x[f'{c}__mean2std'] = x[f'{c}__mean2std'].astype(int)\n",
    "    \n",
    "    x[f'{c}__last2max'] = (x[f'{c}__max']-x[f'{c}__last'])/(x[f'{c}__max'])\n",
    "    x[f'{c}__last2min'] = (x[f'{c}__last']-x[f'{c}__min'])/(x[f'{c}__min'])\n",
    "    x[f'{c}__range'] = (x[f'{c}__max']-x[f'{c}__min'])\n",
    "    \n",
    "    \n",
    "    agg_cols = [f'{c}__min', f'{c}__max', f'{c}__mean', f'{c}__std', f'{c}__first', f'{c}__last', f'{c}__mean2std', \n",
    "                f'{c}__last2max', f'{c}__last2min', f'{c}__range']\n",
    "    x.replace([-np.inf, np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    if x.isna().sum().sum()>0:\n",
    "        if stats_df[stats_df.index==c].shape[0]>0:\n",
    "            train_median = stats_df[stats_df.index==c].iloc[0]\n",
    "            for stats_c_ in train_median.index.values:\n",
    "                x[f'{c}__{stats_c_}'] = x[f'{c}__{stats_c_}'].fillna(value=train_median[stats_c_])\n",
    "        else:\n",
    "            print(c)\n",
    "            for col_ in agg_cols:\n",
    "                x[col_] = x[col_].fillna(value=x[col_].median())\n",
    "        \n",
    "    x[agg_cols] = np.float32(x[agg_cols].values)\n",
    "    pq.write_table(pa.Table.from_pandas(x),  f'{dest_folder}/{c}.parquet', compression = 'GZIP')\n",
    "    agg_files.append(f'{c}.parquet')\n",
    "    \n",
    "    #--calculate the stats ------------------------------------------------------------------\n",
    "\n",
    "    stats.append([c] + x[agg_cols].median().values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T02:43:49.073168Z",
     "iopub.status.busy": "2022-07-12T02:43:49.072699Z",
     "iopub.status.idle": "2022-07-12T02:43:49.095896Z",
     "shell.execute_reply": "2022-07-12T02:43:49.095026Z",
     "shell.execute_reply.started": "2022-07-12T02:43:49.073131Z"
    }
   },
   "outputs": [],
   "source": [
    "stats_cols = ['feat', 'min', 'max', 'mean', 'std', 'first','last', \n",
    "              'mean2std', 'last2max', 'last2min', 'range']\n",
    "\n",
    "stats_df = pd.DataFrame(stats, columns= stats_cols )\n",
    "\n",
    "\n",
    "stats_df.to_csv(f'{dest_folder}/test_agg_median.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for c in str_cat_feats:\n",
    "    df = dd.read_parquet(test_file, columns=['customer_ID', c], engine='pyarrow')\n",
    "    df[c] = df[c].fillna(value='NA') \n",
    "    x0 = df.compute().groupby(\"customer_ID\")[c].value_counts().to_frame()\n",
    "    x0=x0.unstack().fillna(0)\n",
    "    x0.columns = [f'{c0}={c1}' for c0, c1 in x0.columns]\n",
    "    x0[x0.columns.tolist()] = np.float32(x0[x0.columns.tolist()].values)\n",
    "    \n",
    "    x1 = df.compute().groupby(\"customer_ID\").agg({c: ['nunique']})\n",
    "    x1.columns = [f'{c1}__{c2}' for c1, c2 in x1.columns]\n",
    "    x1[x1.columns.tolist()] = np.int32(x1[x1.columns.tolist()].values)\n",
    "    \n",
    "    df = dd.read_parquet(test_file, columns=['customer_ID', 'S_2',c], engine='pyarrow')\n",
    "    x2 = df.compute().sort_values(by='S_2', ascending=True).groupby(\"customer_ID\").agg({c: ['last']})\n",
    "    x2.columns = [f'{c1}__{c2}' for c1, c2 in x2.columns]\n",
    "    col_ = x2.columns[0]\n",
    "    x2[col_] = x2[col_].fillna(value='NA')\n",
    "    dummies_ = pd.get_dummies(x2[col_])\n",
    "    dummy_feats_ =  [f'{col_}={cc}' for cc in dummies_.columns]\n",
    "    dummies_.columns = dummy_feats_\n",
    "    x2[dummy_feats_] = dummies_.values\n",
    "    x2.drop(columns=[col_], inplace=True)\n",
    "    x2.fillna(value=0, inplace=True)\n",
    "    \n",
    "    x = x0.merge(x1, left_index=True, right_index=True, how='left')\n",
    "    x = x.merge(x2, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    pq.write_table(pa.Table.from_pandas(x),  f'{dest_folder}/{c}.parquet', compression = 'GZIP')\n",
    "    agg_files.append(f'{c}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T03:07:30.070854Z",
     "iopub.status.busy": "2022-07-12T03:07:30.070411Z",
     "iopub.status.idle": "2022-07-12T03:13:25.552415Z",
     "shell.execute_reply": "2022-07-12T03:13:25.551210Z",
     "shell.execute_reply.started": "2022-07-12T03:07:30.070818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for c in int_feats + num_cat_feats:\n",
    "    df = dd.read_parquet(test_file, columns=['customer_ID', c], engine='pyarrow')\n",
    "    df[c] = df[c].fillna(value=999) \n",
    "    x0 = df.compute().groupby(\"customer_ID\")[c].value_counts().to_frame()\n",
    "    x0=x0.unstack().fillna(0)\n",
    "    x0.columns = [f'{c0}={c1}' for c0, c1 in x0.columns]\n",
    "    x0[x0.columns.tolist()] = np.float32(x0[x0.columns.tolist()].values)\n",
    "    \n",
    "    x1 = df.compute().groupby(\"customer_ID\").agg({c: ['nunique']})\n",
    "    x1.columns = [f'{c1}__{c2}' for c1, c2 in x1.columns]\n",
    "    x1[x1.columns.tolist()] = np.int32(x1[x1.columns.tolist()].values)\n",
    "    \n",
    "    df = dd.read_parquet(test_file, columns=['customer_ID', 'S_2',c], engine='pyarrow')\n",
    "    df[c] = df[c].fillna(value=999) \n",
    "    x2 = df.compute().sort_values(by='S_2', ascending=True).groupby(\"customer_ID\").agg({c: ['last']})\n",
    "    x2.columns = [f'{c1}__{c2}' for c1, c2 in x2.columns]\n",
    "    \n",
    "    x = x0.merge(x1, left_index=True, right_index=True, how='left')\n",
    "    x = x.merge(x2, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    pq.write_table(pa.Table.from_pandas(x),  f'{dest_folder}/{c}.parquet', compression = 'GZIP')\n",
    "    agg_files.append(f'{c}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T03:14:20.688255Z",
     "iopub.status.busy": "2022-07-12T03:14:20.687840Z",
     "iopub.status.idle": "2022-07-12T03:14:20.694573Z",
     "shell.execute_reply": "2022-07-12T03:14:20.693525Z",
     "shell.execute_reply.started": "2022-07-12T03:14:20.688221Z"
    }
   },
   "outputs": [],
   "source": [
    "def cal_days(v):\n",
    "    m0 = v['S_2=min']\n",
    "    m1 = v['S_2=max']\n",
    "    if m1 is np.nan:\n",
    "        m1 = m0\n",
    "    \n",
    "    return (datetime.strptime(m1, '%Y-%m-%d') - datetime.strptime(m0, '%Y-%m-%d')).days\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T03:20:51.943032Z",
     "iopub.status.busy": "2022-07-12T03:20:51.942085Z",
     "iopub.status.idle": "2022-07-12T03:22:57.812725Z",
     "shell.execute_reply": "2022-07-12T03:22:57.811633Z",
     "shell.execute_reply.started": "2022-07-12T03:20:51.942995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for c in ['S_2']:\n",
    "    df = dd.read_parquet(test_file, columns=['customer_ID', c], engine='pyarrow')\n",
    "    x = df.compute().groupby(\"customer_ID\").agg({c: ['min', 'max', 'count']})\n",
    "    x.columns = [f'{c1}={c2}' for c1, c2 in x.columns]   \n",
    "    \n",
    "    days = []\n",
    "    for _, row in x.iterrows():\n",
    "        days.append(cal_days(row))\n",
    "    x['days']=days\n",
    "    \n",
    "    pq.write_table(pa.Table.from_pandas(x[['S_2=count', 'days']]), f'{dest_folder}/{c}.parquet', compression = 'GZIP')\n",
    "    agg_files.append(f'{c}.parquet')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "df = dd.read_parquet(test_file, columns=['customer_ID'], engine='pyarrow')\n",
    "x = df.compute().groupby(\"customer_ID\").size().to_frame()\n",
    "\n",
    "pq.write_table(pa.Table.from_pandas(x), f'customer_ID.parquet', compression = 'GZIP')\n",
    "agg_files.append(f'customer_ID.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T03:22:57.815118Z",
     "iopub.status.busy": "2022-07-12T03:22:57.814637Z",
     "iopub.status.idle": "2022-07-12T03:22:57.821966Z",
     "shell.execute_reply": "2022-07-12T03:22:57.820952Z",
     "shell.execute_reply.started": "2022-07-12T03:22:57.815086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, ['B_1.parquet'], 189)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agg_files), agg_files[:1], len(set(agg_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T03:22:57.823881Z",
     "iopub.status.busy": "2022-07-12T03:22:57.823302Z",
     "iopub.status.idle": "2022-07-12T03:22:57.834108Z",
     "shell.execute_reply": "2022-07-12T03:22:57.833041Z",
     "shell.execute_reply.started": "2022-07-12T03:22:57.823850Z"
    }
   },
   "outputs": [],
   "source": [
    "agg_files = list(set(agg_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T03:24:03.264173Z",
     "iopub.status.busy": "2022-07-12T03:24:03.263759Z",
     "iopub.status.idle": "2022-07-12T03:32:51.826455Z",
     "shell.execute_reply": "2022-07-12T03:32:51.825311Z",
     "shell.execute_reply.started": "2022-07-12T03:24:03.264137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "Wall time: 15min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# df = pd.read_csv('/kaggle/input/amex-default-prediction/sample_submission.csv')\n",
    "df = pd.read_csv('amex/sample_submission.csv')\n",
    "\n",
    "df = df[['customer_ID']].copy(deep=True)\n",
    "\n",
    "for i, file in enumerate(agg_files):\n",
    "    df_ = pd.read_parquet(f'{dest_folder}/{file}').reset_index()\n",
    "    df = df.merge(df_,on=['customer_ID'], how='left')\n",
    "        \n",
    "    del df_\n",
    "    gc.collect()\n",
    "        \n",
    "print(i)\n",
    "pq.write_table(pa.Table.from_pandas(df), f'{dest_folder}/agg_test_all_rev3.parquet', compression = 'GZIP')\n",
    "# del df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T03:35:52.334998Z",
     "iopub.status.busy": "2022-07-12T03:35:52.334345Z",
     "iopub.status.idle": "2022-07-12T03:35:52.344887Z",
     "shell.execute_reply": "2022-07-12T03:35:52.344003Z",
     "shell.execute_reply.started": "2022-07-12T03:35:52.334944Z"
    }
   },
   "source": [
    "len(agg_files)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T03:35:53.462802Z",
     "iopub.status.busy": "2022-07-12T03:35:53.462435Z",
     "iopub.status.idle": "2022-07-12T03:35:53.801794Z",
     "shell.execute_reply": "2022-07-12T03:35:53.800718Z",
     "shell.execute_reply.started": "2022-07-12T03:35:53.462772Z"
    }
   },
   "source": [
    "for file in agg_files:\n",
    "    Path(file).unlink()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T03:35:55.903420Z",
     "iopub.status.busy": "2022-07-12T03:35:55.902736Z",
     "iopub.status.idle": "2022-07-12T03:35:55.911730Z",
     "shell.execute_reply": "2022-07-12T03:35:55.910462Z",
     "shell.execute_reply.started": "2022-07-12T03:35:55.903385Z"
    }
   },
   "source": [
    "files = next(os.walk('.'))[2]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(f'{dest_folder}/agg_test_all_rev3.parquet', engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_feats_ = list(set(float_feats)-set(num_cat_feats)-set(int_feats))\n",
    "len(float_feats_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1849"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols2 = df.columns.tolist()\n",
    "all_cols2.sort()\n",
    "len(all_cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_cnt = df.isna().sum()\n",
    "na_cnt[na_cnt>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eps =  1e-8\n",
    "log_feats = []\n",
    "\n",
    "for c in all_cols2:\n",
    "    \n",
    "    if c in ['customer_ID', 'target']:\n",
    "        continue\n",
    "    \n",
    "    if df[c].dtype not in ['float64', 'float32']:\n",
    "        continue\n",
    "        \n",
    "    if '__' in c:\n",
    "        c0, c1 = c.split('__')\n",
    "        if (c0 in float_feats_) & (c1 in ['last', 'mean']):\n",
    "            if df[c].min()>0:\n",
    "                df[f'{c}__log'] = np.log(df[c].values + eps)\n",
    "                df[f'{c}__log'].replace([-np.inf, np.inf], np.nan, inplace=True)\n",
    "                df[f'{c}__log'] = df[f'{c}__log'].fillna(df[f'{c}__log'].median())\n",
    "                log_feats.append(f'{c}__log')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "float64_cols = df.select_dtypes(include=['float64']).columns.tolist()\n",
    "df[float64_cols] = np.float32(df[float64_cols].values)\n",
    "#---convert int64 to int32\n",
    "int64_cols = df.select_dtypes(include=['int64']).columns.tolist()\n",
    "df[int64_cols] = np.int32(df[int64_cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_cnt = df.isna().sum()\n",
    "na_cnt[na_cnt>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 924621 entries, 0 to 924620\n",
      "Columns: 2116 entries, customer_ID to S_9__mean__log\n",
      "dtypes: float32(2090), int32(13), int64(2), object(1), uint8(10)\n",
      "memory usage: 7.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pq.write_table(pa.Table.from_pandas(df), f'{dest_folder}/agg_test_all_rev3.parquet', compression = 'GZIP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlation with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2116"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_cols = df.columns.tolist()\n",
    "all_test_cols.sort()\n",
    "len(all_test_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_target = pd.read_csv('amex/train/corr_w_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_feats = corr_target['feat'].values.tolist()\n",
    "all_train_feats.sort()\n",
    "len(all_train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B_28__mean__log', 'D_64=-1', 'D_64__last=-1', 'D_66=0.0', 'D_68=0.0'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all_train_feats)-set(all_test_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2115"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_feats = list(set(all_train_feats) & set(all_test_cols))\n",
    "len(both_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
